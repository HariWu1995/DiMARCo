{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://i.postimg.cc/26RtyM0s/3221asdf.jpg\" width=690>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"color: white; border: lightgreen solid; font-weight: bold; font-size: 120%; text-align: center; padding: 12.0px; background: black\">0. ENVIRONMENT</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python\n",
    "# !pip install spatial-correlation-sampler --no-build-isolation\n",
    "# !pip install tensorflow\n",
    "# !pip install diffusers==0.30.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.arckit as arckit\n",
    "import src.utils as utils\n",
    "\n",
    "from src.noise import alpha_schedule, beta_schedule\n",
    "from src.datasets import iARCDatasetNaive as Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_trigrids(i, o, e = None):\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2 if e is None else 3)\n",
    "    \n",
    "#     fig.add_trace(go.Heatmap(z=i, name='Input'), row=1, col=1)\n",
    "#     fig.add_trace(go.Heatmap(z=o, name='Output'), row=1, col=2)\n",
    "\n",
    "#     if e is not None:\n",
    "#         fig.add_trace(go.Heatmap(z=e, name='Error'), row=1, col=3)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "\n",
    "def plot_trigrids(i, o, e = None):\n",
    "\n",
    "    visual_kwargs = dict(text_auto=True, width=400, height=400)\n",
    "    \n",
    "    fig = px.imshow(i, title='input', **visual_kwargs)\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.imshow(o, title='output', **visual_kwargs)\n",
    "    fig.show()\n",
    "    \n",
    "    fig = px.imshow(e, title='error', **visual_kwargs)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"color: white; border: lightgreen solid; font-weight: bold; font-size: 120%; text-align: center; padding: 12.0px; background: black\">1. DATA LOADING</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'iarc2daug'\n",
    "model_name = 'unet'\n",
    "trainer_name = 'dimarco'\n",
    "\n",
    "checkpoint_path = f'../results/{trainer_name}-{data_name}-{model_name}'\n",
    "\n",
    "checkpoint_config = utils.load_yaml(os.path.join(checkpoint_path, 'config.yaml'))\n",
    "checkpoint_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint_config['diffuser']['noise_schedule'] == 'alpha':\n",
    "    noise_schedule = alpha_schedule\n",
    "else:\n",
    "    noise_schedule = beta_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load data\n",
    "dataset_dir = Path('../data/competition')\n",
    "# dataset_dir = Path('/kaggle/input/arc-prize-2024/')\n",
    "\n",
    "train_challenges = utils.load_json(dataset_dir / 'arc-agi_training_challenges.json')\n",
    "train_solutions  = utils.load_json(dataset_dir / 'arc-agi_training_solutions.json')\n",
    "\n",
    "eval_challenges = utils.load_json(dataset_dir / 'arc-agi_evaluation_challenges.json')\n",
    "eval_solutions  = utils.load_json(dataset_dir / 'arc-agi_evaluation_solutions.json')\n",
    "\n",
    "test_challenges = utils.load_json(dataset_dir / 'arc-agi_test_challenges.json')\n",
    "\n",
    "## Format data: combine train & eval datasets\n",
    "task_set = arckit.format_data(train_challenges, train_solutions, \n",
    "                               eval_challenges,  eval_solutions)\n",
    "\n",
    "task_set = arckit.load_data(task_set, eval=False, combine=True)\n",
    "\n",
    "## Dataloader\n",
    "dataset = Dataset(task_set=task_set, **checkpoint_config['data'])\n",
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div  style=\"color:white; border:lightgreen solid;  font-weight:bold; font-size:120%; text-align:center;padding:12.0px; background:black\">2. MODEL EVALUATION</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_config = checkpoint_config['model']\n",
    "model_config.update(dict(in_channels = 1, \n",
    "                        out_channels = 1))\n",
    "\n",
    "if model_config['backbone'] == 'catunet':\n",
    "    from src.models import CatUNet as UNet\n",
    "\n",
    "elif model_config['backbone'] == 'dilunet':\n",
    "    from src.models import DilUNet as UNet\n",
    "\n",
    "elif model_config['backbone'] == 'munet':\n",
    "    from src.models import mUNet as UNet\n",
    "\n",
    "else:\n",
    "    from src.models import UNet\n",
    "\n",
    "model = UNet(**model_config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load checkpoint\n",
    "state_dict = torch.load(os.path.join(checkpoint_path, 'model-best.pt'), map_location=device)\n",
    "\n",
    "if 'model' in state_dict:\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "else:\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 123\n",
    "batch_idx = 1\n",
    "noise_scale = 0.19\n",
    "denoise_steps = 20\n",
    "# denoise_steps = checkpoint_config['diffuser']['denoising_steps']\n",
    "\n",
    "x = dataset[sample_idx][0][batch_idx]\n",
    "\n",
    "x = x.unsqueeze(dim=0).unsqueeze(dim=1).to(device)\n",
    "\n",
    "if model_config['backbone'] == 'catunet':\n",
    "    # x can be considered as mask / magnitude of category `c`\n",
    "    c = x\n",
    "    x = torch.where(x >= 0, 1., 0)            \n",
    "else:\n",
    "    # normalize num_classes = 10, background = -1\n",
    "    x = torch.where(x >= 0, x/10, x)\n",
    "\n",
    "# Add noise\n",
    "n = (noise_scale * torch.rand(x.shape[0])).to(device)\n",
    "x_n = noise_schedule(x, n)\n",
    "x_n = x_n.to(device)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    if model_config['backbone'] == 'catunet':\n",
    "        x = c\n",
    "        y = model(x_n, c, t=denoise_steps)\n",
    "    else:\n",
    "        y = model(x_n, t=denoise_steps)\n",
    "        \n",
    "x = x.squeeze().detach().cpu().numpy()\n",
    "y = y.squeeze().detach().cpu().numpy()\n",
    "\n",
    "if model_config['backbone'] != 'catunet':\n",
    "    x *= 10\n",
    "    y *= 10\n",
    "\n",
    "x = np.rint(x)\n",
    "y = np.rint(y)\n",
    "\n",
    "x = np.where(x >= 0, x, -1)\n",
    "y = np.where(y >= 0, y, -1)\n",
    "\n",
    "e = np.abs(y - x)\n",
    "\n",
    "plot_trigrids(x, y, e)\n",
    "\n",
    "print('Error stats:')\n",
    "print('\\t Max:', np.max(e))\n",
    "print('\\t Min:', np.min(e))\n",
    "print('\\t Avg:', np.mean(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color: #D35142; font-weight: bold; font-size: 100%; text-align :center; padding: 12.0px; background: #ffffff\"> Thank you for your reading! </div>\n",
    "### <div style=\"color: #D35142; font-weight: bold; font-size: 100%; text-align: center; padding: 12.0px; background: #ffffff\"> Please upvote this notebook if you consider it helpful. Your feedback is my motivation to contribute more ! </div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
